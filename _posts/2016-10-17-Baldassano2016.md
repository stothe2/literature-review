---
layout: post
title: "Discovering event structure in continuous narrative perception and memory"
date: 2016-10-17
category: Sequence learning
---

# Summary

Paper describes unified theory of how continuous perceptual stimuli is processed in our brain.

1. Narrative stimulus is chunked into segments. This chunking can occur at different timescales. One view is that we use a distributed topographical hierarchy of timescales: short timescales (10ms-100ms) in early sensory regions, longer timescales (10s-100s) in higher-order areas. Progressive integration.

2. At the top of the hierarchy, event segments are represented in abstract form called a situation model (so no difference between visual vs auditory situation model if the narrative is the same).

3. Situation models are stored in hippocampus (long-term memory) at the end of each event boundary (post-boundary encoding). Important to note that the event boundary used is the one for situation models, i.e., high-level regions / longer timescales.

4. Observer event boundaries are most likely to match assumed event boundaries in high-level regions (i.e., event boundaries of situtation models).

Assumes discrete event representations (hidden states), where each has a distict signature (a multi-voxel fMRI pattern) that is present througout the event.

# Methods

HMM-based event segmentation model. Fitting = estimating *when* the transitions occur, and also the mean neural pattern for each event. Optimal # of events selected by sweeping over a range of values and maximizing held-out data.

TODO: fill in model details (wait for Janice's talk?).

# Takeaways

